# PPO Finetuning Configuration
seed: 42
wandb_log: true
from_scratch: false

defaults:
  - context
  - tokenizer: smiles
  - experiment: finetune_base
  - loader: ${experiment}
  - data: zinc
  - optim: adamw
  - sys: runtime
  - log: wandb
  - ckpt: default
  - ppo: default
  - reward: default
  - rl_train_cfg: default

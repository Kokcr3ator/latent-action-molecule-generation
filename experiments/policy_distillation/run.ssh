export DATASET="zinc"

python3 -m scripts.train data=$DATASET \
model=pretrain-policy \
train_cfg.batch_size=256 \
tokenizer.vocab_size=500 \
loader.controllable_gpt_path='/workspace/giortom/InterDiff/ckpts/controllable_gpt_bs_256_vocab500_seed42/best.pt'

# if you want to change the batch_size:
# python3 -m scripts.train data=$DATASET train_cfg.batch_size=bs

# if you want to change the vocabular size: 
# python3 -m scripts.train data=$DATASET tokenizer.vocab_size=vs

# in general just have a look in interdiff/conf/config.yaml...

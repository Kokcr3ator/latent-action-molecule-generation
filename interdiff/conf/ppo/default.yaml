# PPO Hyperparameters
_target_: interdiff.ppo.HParams
num_actions: ${tokenizer.vocab_size}
num_envs: 16
num_steps: 256
budget: 1000000
num_epochs: 4
num_minibatches: 8
clip_eps: 0.2
ent_coef: 0.01
max_episode_length: ${context.seq_len}
vf_coef: 0.5
max_grad_norm: 1.0
lr: 3e-4
normalise_advantage: true
clip_value_loss: true
gae_lambda: 0.95
discount: 1.0
weight_decay: 0.01
anneal_lr: true
lambda_kld: 0.1  # KL divergence penalty coefficient (0 = disabled)
log_frequency: 1
log_to_wandb: ${wandb_log}
wandb_project_name: ${experiment.wandb_project}
save_dir: ${rl_train_cfg.ckpt_path}
eval_frequency: 1
random_start: False

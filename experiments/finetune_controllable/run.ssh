# Load from pretrained model
python3 -m scripts.train_ppo --config configs/finetune_controllable.yaml \
  --override ckpt.init_from=resume \
             ckpt.path="/path/to/ckpts/interdiff_bs512_vocab500_seed42" \
             ckpt.ckpt_name="best.pt" \
             loader.ckpt_controllable_path="/path/to/ckpts/policydistillation_bs_256_vocab500_seed42" \
             loader.ckpt_name="best.pt"

# If you want to train from scratch the model add:
# --override from_scratch=True

# Use LogP reward
# python3 -m scripts.train_ppo --config configs/finetune_controllable.yaml --override reward.task=logp

# Customize PPO hyperparameters
# python3 -m scripts.train_ppo --config configs/finetune_controllable.yaml --override ppo.num_envs=64 ppo.lr=1e-4 ppo.budget=2000000

# Disable wandb logging
# python3 -m scripts.train_ppo --config configs/finetune_controllable.yaml --override wandb_log=false
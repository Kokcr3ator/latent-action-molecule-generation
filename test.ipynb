{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0adb8985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interdiff.io import load_tokenizer\n",
    "from safetensors.torch import load_file as load_safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2eaecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Tokenizer file not found at /home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/tokenizer.json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tok \u001b[38;5;241m=\u001b[39m \u001b[43mload_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/tokenizer.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m load_safetensors(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/dataset.safetensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/workspace/giortom/InterDiff/interdiff/io.py:71\u001b[0m, in \u001b[0;36mload_tokenizer\u001b[0;34m(tokenizer_path)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a tokenizer from a JSON file.\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(tokenizer_path):\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer file not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading tokenizer from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m tokenizers\u001b[38;5;241m.\u001b[39mTokenizer\u001b[38;5;241m.\u001b[39mfrom_file(tokenizer_path)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Tokenizer file not found at /home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/tokenizer.json"
     ]
    }
   ],
   "source": [
    "tok = load_tokenizer('/home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/tokenizer.json')\n",
    "tokens = load_safetensors('/home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/dataset.safetensors')\n",
    "tokens = tokens['dataset']\n",
    "\n",
    "prova = tokens[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a7bc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/giortom/envs/gtclearance/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 9.00M\n",
      "number of parameters: 9.00M\n",
      "number of parameters: 9.00M\n",
      "num decayed parameter tensors: 55, with 27,337,728 parameters\n",
      "num non-decayed parameter tensors: 27, with 10,368 parameters\n",
      "using fused AdamW: True\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from scripts.train import run_tokenisation\n",
    "\n",
    "\n",
    "initialize(config_path=\"interdiff/conf\", version_base=None)\n",
    "cfg = compose(config_name=\"config\")\n",
    "\n",
    "\n",
    "model = instantiate(cfg.model)\n",
    "train_cfg = instantiate(cfg.train_cfg)\n",
    "optim = instantiate(cfg.optim, model=model)\\\n",
    "sched = instantiate(cfg.sched, optimizer=optim)\n",
    "# logger = instantiate(cfg.log)\n",
    "\n",
    "save_path = '/workspace/giortom/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_500/dataset.safetensors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8112954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cfg.train_cfg.device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f051d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = instantiate(cfg.trainer, model=model, scheduler=sched, optimizer=optim, logger=None, train_cfg=train_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfb4eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20: train loss 17.659776592254637\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loaders \u001b[38;5;241m=\u001b[39m instantiate(cfg\u001b[38;5;241m.\u001b[39mloader, dataset_path \u001b[38;5;241m=\u001b[39m save_path)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/giortom/InterDiff/interdiff/trainers/base.py:108\u001b[0m, in \u001b[0;36mTrainerBase.fit\u001b[0;34m(self, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m    106\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_loss(\u001b[38;5;28mnext\u001b[39m(dl))\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 108\u001b[0m running \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_clip \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_clip \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loaders = instantiate(cfg.loader, dataset_path = save_path)\n",
    "trainer.fit(loaders.train_loader, loaders.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d83540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/giortom/envs/gtclearance/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from interdiff.modules import TransformerConfig\n",
    "\n",
    "\n",
    "initialize(config_path=\"interdiff/conf\", version_base=None)\n",
    "cfg = compose(config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6997753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 9.00M\n",
      "number of parameters: 9.00M\n",
      "number of parameters: 9.00M\n",
      "num decayed parameter tensors: 55, with 27,337,728 parameters\n",
      "num non-decayed parameter tensors: 27, with 10,368 parameters\n",
      "using fused AdamW: True\n"
     ]
    }
   ],
   "source": [
    "from interdiff.models import ControllableGPT\n",
    "model = instantiate(cfg.model)\n",
    "train_cfg = instantiate(cfg.train_cfg)\n",
    "optim = instantiate(cfg.optim, model=model)\n",
    "sched = instantiate(cfg.sched, optimizer=optim)\n",
    "# logger = instantiate(cfg.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8990a792",
   "metadata": {},
   "outputs": [
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'interdiff.data.ControllableGPTLoader.ControllableGPTLoader':\nFileNotFoundError('No such file or directory: /home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/dataset.safetensors')\nfull_key: loader",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/workspace/giortom/envs/gtclearance/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_target_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/workspace/giortom/InterDiff/interdiff/data/ControllableGPTLoader.py:108\u001b[0m, in \u001b[0;36mControllableGPTLoader.__init__\u001b[0;34m(self, dataset_path, batch_size, seed, val_ratio)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_path: \u001b[38;5;28mstr\u001b[39m, batch_size: \u001b[38;5;28mint\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m, val_ratio: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loader \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dataloaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/giortom/InterDiff/interdiff/data/ControllableGPTLoader.py:73\u001b[0m, in \u001b[0;36mbuild_dataloaders\u001b[0;34m(path, seed, val_ratio, batch_size, shuffle_train, drop_last, pin_memory)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_ratio must be in (0, 1).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m full \u001b[38;5;241m=\u001b[39m \u001b[43m_load_tensor_from_safetensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ControllableGPTDataset(full)\n",
      "File \u001b[0;32m/workspace/giortom/InterDiff/interdiff/data/ControllableGPTLoader.py:38\u001b[0m, in \u001b[0;36m_load_tensor_from_safetensors\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mLoads a single tensor from a .safetensors file as a torch tensor.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msafe_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     39\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(f\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: /home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/dataset.safetensors",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaders \u001b[38;5;241m=\u001b[39m \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/dataset.safetensors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m instantiate(cfg\u001b[38;5;241m.\u001b[39mtrainer, model\u001b[38;5;241m=\u001b[39mmodel, scheduler\u001b[38;5;241m=\u001b[39msched, optimizer\u001b[38;5;241m=\u001b[39moptim, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, train_cfg\u001b[38;5;241m=\u001b[39mtrain_cfg)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# trainer.fit(loaders.train_loader, loaders.val_loader)\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/giortom/envs/gtclearance/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     _convert_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mCONVERT, ConvertMode\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[1;32m    224\u001b[0m     _partial_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mPARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_partial_\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf\u001b[38;5;241m.\u001b[39mis_list(config):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     config_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m/workspace/giortom/envs/gtclearance/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 value \u001b[38;5;241m=\u001b[39m instantiate_node(\n\u001b[1;32m    343\u001b[0m                     value, convert\u001b[38;5;241m=\u001b[39mconvert, recursive\u001b[38;5;241m=\u001b[39mrecursive\n\u001b[1;32m    344\u001b[0m                 )\n\u001b[1;32m    345\u001b[0m             kwargs[key] \u001b[38;5;241m=\u001b[39m _convert_node(value, convert)\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_target_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;66;03m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert \u001b[38;5;241m==\u001b[39m ConvertMode\u001b[38;5;241m.\u001b[39mALL \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    352\u001b[0m         convert \u001b[38;5;129;01min\u001b[39;00m (ConvertMode\u001b[38;5;241m.\u001b[39mPARTIAL, ConvertMode\u001b[38;5;241m.\u001b[39mOBJECT)\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mobject_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    354\u001b[0m     ):\n",
      "File \u001b[0;32m/workspace/giortom/envs/gtclearance/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[1;32m     96\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error in call to target 'interdiff.data.ControllableGPTLoader.ControllableGPTLoader':\nFileNotFoundError('No such file or directory: /home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/dataset.safetensors')\nfull_key: loader"
     ]
    }
   ],
   "source": [
    "loaders = instantiate(cfg.loader, dataset_path = '/home/tommaso/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_5000/dataset.safetensors')\n",
    "trainer = instantiate(cfg.trainer, model=model, scheduler=sched, optimizer=optim, logger=None, train_cfg=train_cfg)\n",
    "# trainer.fit(loaders.train_loader, loaders.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283a5c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 22:22:05,559 INFO generate_actions: Loading ControllableGPT model from /workspace/giortom/InterDiff/ckpts/interdiff_bs512_vocab5000_seed42/best.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 9.00M\n",
      "number of parameters: 9.00M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 22:22:06,442 INFO root: Model ControllableGPT successfully loaded from /workspace/giortom/InterDiff/ckpts/interdiff_bs512_vocab5000_seed42/best.pt\n",
      "2025-12-01 22:22:06,472 INFO generate_actions: Loading tokenized dataset from /workspace/giortom/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_500/dataset.safetensors\n",
      "2025-12-01 22:22:06,473 INFO generate_actions: Generating actions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 9.00M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:50<00:00,  1.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/workspace/giortom/InterDiff/data/processed/zinc_tok_seqlen_128_vocabsize_500/actions_dataset.safetensors'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interdiff.models import ControllableGPT\n",
    "from scripts.generate_actions import run_action_generation\n",
    "import torch\n",
    "\n",
    "controllable_gpt_path = '/workspace/giortom/InterDiff/ckpts/interdiff_bs512_vocab5000_seed42/best.pt'\n",
    "\n",
    "run_action_generation(controllable_gpt_path = controllable_gpt_path,\n",
    "                      tokenized_dataset_path = '/workspace/giortom/InterDiff/interdiff/data/processed/zinc_tok_seqlen_128_vocabsize_500/dataset.safetensors',\n",
    "                      batch_size = 4096,\n",
    "                      pad_token_id = 0,\n",
    "                      out_dir = '/workspace/giortom/InterDiff/data/processed/zinc_tok_seqlen_128_vocabsize_500/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44744815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a safetensrors file\n",
    "import safetensors.torch\n",
    "import os\n",
    "import torch\n",
    "\n",
    "tensor_p = '/workspace/giortom/InterDiff/data/processed/zinc_tok_seqlen_128_vocabsize_500/actions_dataset.safetensors'\n",
    "\n",
    "loaded = safetensors.torch.load_file(tensor_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0589073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "reward = torch.zeros_like(torch.zeros(32))\n",
    "action = torch.randint(0, 10, (32,))\n",
    "new_reward = torch.ones_like(reward) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae69dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reward = torch.ones(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ec294d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward.where((action != 4).unsqueeze(-1), new_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1c1123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
